{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8a1bc32-682b-4af1-9486-41aff608a63a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "HOTEL BOOKING CANCELLATION PREDICTION & RECOMMENDATION SYSTEM\n",
      "================================================================================\n",
      "\n",
      "Original shape: (36275, 19)\n",
      "Correcting 37 invalid dates (2018-02-29 ‚Üí 2018-02-28)\n",
      "After preprocessing: 36275 records\n",
      "\n",
      "Train: (29020, 21), Test: (7255, 21)\n",
      "\n",
      "‚ö†Ô∏è Using ORIGINAL data (No scaling applied)\n",
      "Feature columns: 30\n",
      "  Categorical (encoded): 15\n",
      "  Numerical (original): 15\n",
      "\n",
      "Target encoding: {'Canceled': 0, 'Not_Canceled': 1}\n",
      "  0 = Canceled, 1 = Not_Canceled\n",
      "\n",
      "After SMOTE: 39024 samples\n",
      "Class balance: {0: 19512, 1: 19512}\n",
      "\n",
      "================================================================================\n",
      "APPROACH 1: STANDARD MODELS (No Clustering)\n",
      "================================================================================\n",
      "\n",
      "--- Random Forest (Standard) ---\n",
      "Train - Acc: 0.9418, Prec: 0.9498, Rec: 0.9330, F1: 0.9413\n",
      "Test  - Acc: 0.8976, Prec: 0.8644, Rec: 0.8153, F1: 0.8391\n",
      "‚úì Saved: confusion_matrix_rf_standard.png\n",
      "\n",
      "--- XGBoost (Standard) ---\n",
      "Train - Acc: 0.9078, Prec: 0.9184, Rec: 0.8951, F1: 0.9066\n",
      "Test  - Acc: 0.8852, Prec: 0.8374, Rec: 0.8061, F1: 0.8214\n",
      "‚úì Saved: confusion_matrix_xgb_standard.png\n",
      "\n",
      "================================================================================\n",
      "APPROACH 2: CLUSTER-BASED MODELS\n",
      "================================================================================\n",
      "\n",
      "Cluster Distribution:\n",
      "Train: {0: 27763, 1: 11261}\n",
      "Test: {0: 5539, 1: 1716}\n",
      "Cluster 0: Size=27763, Cancellation Rate=37.83%\n",
      "Cluster 1: Size=11261, Cancellation Rate=79.99%\n",
      "\n",
      "--- Cluster 0 ---\n",
      "RF  - Acc: 0.9315, Prec: 0.9203, Rec: 0.8967, F1: 0.9083\n",
      "XGB - Acc: 0.8927, Prec: 0.8718, Rec: 0.8400, F1: 0.8556\n",
      "\n",
      "--- Cluster 1 ---\n",
      "RF  - Acc: 0.9886, Prec: 0.9949, Rec: 0.9909, F1: 0.9929\n",
      "XGB - Acc: 0.9764, Prec: 0.9887, Rec: 0.9817, F1: 0.9852\n",
      "\n",
      "--- Cluster Models: Overall Test Performance ---\n",
      "RF  - Acc: 0.8988, Prec: 0.8653, Rec: 0.8187, F1: 0.8413\n",
      "XGB - Acc: 0.8892, Prec: 0.8430, Rec: 0.8132, F1: 0.8278\n",
      "‚úì Saved: confusion_matrix_rf_cluster.png\n",
      "‚úì Saved: confusion_matrix_xgb_cluster.png\n",
      "\n",
      "--- Per-Cluster Test Performance ---\n",
      "\n",
      "Cluster 0:\n",
      "RF  - Acc: 0.8859, Prec: 0.7683, Rec: 0.6931, F1: 0.7288\n",
      "XGB - Acc: 0.8729, Prec: 0.7252, Rec: 0.6849, F1: 0.7045\n",
      "\n",
      "Cluster 1:\n",
      "RF  - Acc: 0.9406, Prec: 0.9589, Rec: 0.9523, F1: 0.9556\n",
      "XGB - Acc: 0.9417, Prec: 0.9630, Rec: 0.9497, F1: 0.9563\n",
      "\n",
      "================================================================================\n",
      "COMPREHENSIVE METRICS SUMMARY\n",
      "================================================================================\n",
      "\n",
      "       Model  Dataset  Accuracy  Precision   Recall  F1-Score\n",
      " RF Standard    Train  0.941831   0.949760 0.933016  0.941313\n",
      " RF Standard     Test  0.897588   0.864407 0.815313  0.839143\n",
      "XGB Standard    Train  0.907826   0.918441 0.895141  0.906642\n",
      "XGB Standard     Test  0.885183   0.837413 0.806058  0.821436\n",
      "  RF Cluster Train-C0  0.931528   0.920274 0.896706  0.908337\n",
      " XGB Cluster Train-C0  0.892735   0.871838 0.839966  0.855605\n",
      "  RF Cluster Train-C1  0.988633   0.994873 0.990897  0.992881\n",
      " XGB Cluster Train-C1  0.976379   0.988708 0.981683  0.985183\n",
      "  RF Cluster     Test  0.898828   0.865273 0.818679  0.841332\n",
      " XGB Cluster     Test  0.889180   0.843000 0.813210  0.827837\n",
      "  RF Cluster  Test-C0  0.885900   0.768326 0.693061  0.728755\n",
      " XGB Cluster  Test-C0  0.872901   0.725151 0.684898  0.704450\n",
      "  RF Cluster  Test-C1  0.940559   0.958916 0.952257  0.955575\n",
      " XGB Cluster  Test-C1  0.941725   0.963028 0.949653  0.956294\n",
      "\n",
      "‚úì Saved: model_metrics_comprehensive.csv\n",
      "\n",
      "================================================================================\n",
      "MODEL COMPARISON (Test Set)\n",
      "================================================================================\n",
      "\n",
      "Test Performance Comparison:\n",
      "       Model Dataset  Accuracy  Precision   Recall  F1-Score\n",
      " RF Standard    Test  0.897588   0.864407 0.815313  0.839143\n",
      "XGB Standard    Test  0.885183   0.837413 0.806058  0.821436\n",
      "  RF Cluster    Test  0.898828   0.865273 0.818679  0.841332\n",
      " XGB Cluster    Test  0.889180   0.843000 0.813210  0.827837\n",
      "\n",
      "üèÜ BEST MODEL BY F1-SCORE: RF Cluster\n",
      "   Accuracy: 0.8988\n",
      "   Precision: 0.8653\n",
      "   Recall: 0.8187\n",
      "   F1-Score: 0.8413\n",
      "\n",
      "üéØ BEST MODEL BY ACCURACY: RF Cluster\n",
      "   Accuracy: 0.8988\n",
      "   Precision: 0.8653\n",
      "   Recall: 0.8187\n",
      "   F1-Score: 0.8413\n",
      "\n",
      "================================================================================\n",
      "CREATING VISUALIZATION\n",
      "================================================================================\n",
      "‚úì Saved: model_comparison_metrics.png\n",
      "\n",
      "================================================================================\n",
      "FEATURE IMPORTANCE ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "Top 15 Features (Overall):\n",
      "                       feature  importance\n",
      "        no_of_special_requests    0.185863\n",
      "                     lead_time    0.164061\n",
      "            avg_price_per_room    0.139658\n",
      "                 arrival_month    0.075862\n",
      "                   arrival_day    0.056682\n",
      "          no_of_weekend_nights    0.047271\n",
      "    market_segment_type_Online    0.046463\n",
      "             no_of_week_nights    0.040537\n",
      "                  no_of_adults    0.038586\n",
      "             arrival_dayofweek    0.033961\n",
      "                  arrival_year    0.031730\n",
      "               arrival_quarter    0.031645\n",
      "   market_segment_type_Offline    0.031436\n",
      "room_type_reserved_Room_Type 4    0.012842\n",
      "type_of_meal_plan_Not Selected    0.012722\n",
      "‚úì Saved: feature_importance_overall.png\n",
      "\n",
      "================================================================================\n",
      "FEATURE IMPORTANCE BY CLUSTER\n",
      "================================================================================\n",
      "\n",
      "--- Cluster 0 ---\n",
      "\n",
      "Top 15 Features:\n",
      "                       feature  importance\n",
      "        no_of_special_requests    0.242725\n",
      "                     lead_time    0.152686\n",
      "            avg_price_per_room    0.086959\n",
      "                 arrival_month    0.065332\n",
      "    market_segment_type_Online    0.062893\n",
      "                   arrival_day    0.050457\n",
      "          no_of_weekend_nights    0.049471\n",
      "             no_of_week_nights    0.044121\n",
      "               arrival_quarter    0.033758\n",
      "   market_segment_type_Offline    0.033357\n",
      "                  arrival_year    0.031178\n",
      "             arrival_dayofweek    0.031082\n",
      "                  no_of_adults    0.026897\n",
      "type_of_meal_plan_Not Selected    0.016199\n",
      "room_type_reserved_Room_Type 4    0.016021\n",
      "‚úì Saved: feature_importance_cluster_0.png\n",
      "\n",
      "--- Cluster 1 ---\n",
      "\n",
      "Top 15 Features:\n",
      "                      feature  importance\n",
      "           avg_price_per_room    0.192357\n",
      "                    lead_time    0.175435\n",
      "       no_of_special_requests    0.129002\n",
      "                arrival_month    0.086391\n",
      "                  arrival_day    0.062906\n",
      "                 no_of_adults    0.050275\n",
      "         no_of_weekend_nights    0.045072\n",
      "            no_of_week_nights    0.036953\n",
      "            arrival_dayofweek    0.036841\n",
      "                 arrival_year    0.032282\n",
      "   market_segment_type_Online    0.030032\n",
      "              arrival_quarter    0.029532\n",
      "  market_segment_type_Offline    0.029516\n",
      "type_of_meal_plan_Meal Plan 2    0.018120\n",
      "           is_weekend_arrival    0.014033\n",
      "‚úì Saved: feature_importance_cluster_1.png\n",
      "\n",
      "--- Creating Cluster Comparison Plot ---\n",
      "‚úì Saved: feature_importance_clusters_comparison.png\n",
      "\n",
      "================================================================================\n",
      "PARTIAL DEPENDENCE PLOTS (Top 4 Most Important Features - Overall)\n",
      "================================================================================\n",
      "\n",
      "Creating PDPs for top 4 features: ['no_of_special_requests', 'lead_time', 'avg_price_per_room', 'arrival_month']\n",
      "\n",
      "--- Processing PDP for: no_of_special_requests ---\n",
      "  Type: Numerical\n",
      "  Min: 0.00, Max: 5.00, Mean: 0.62, Std: 0.79\n",
      "‚úì Saved: pdp_overall_no_of_special_requests.png\n",
      "\n",
      "--- Processing PDP for: lead_time ---\n",
      "  Type: Numerical\n",
      "  Min: 0.00, Max: 443.00, Mean: 85.13, Std: 85.92\n",
      "‚úì Saved: pdp_overall_lead_time.png\n",
      "\n",
      "--- Processing PDP for: avg_price_per_room ---\n",
      "  Type: Numerical\n",
      "  Min: 0.00, Max: 540.00, Mean: 103.53, Std: 35.15\n",
      "‚úì Saved: pdp_overall_avg_price_per_room.png\n",
      "\n",
      "--- Processing PDP for: arrival_month ---\n",
      "  Type: Numerical\n",
      "  Min: 1.00, Max: 12.00, Mean: 7.43, Std: 3.07\n",
      "‚úì Saved: pdp_overall_arrival_month.png\n",
      "\n",
      "================================================================================\n",
      "PARTIAL DEPENDENCE PLOTS BY CLUSTER (Top 4 Features)\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "CLUSTER 0 - PARTIAL DEPENDENCE PLOTS\n",
      "================================================================================\n",
      "\n",
      "Top 4 features for Cluster 0: ['no_of_special_requests', 'lead_time', 'avg_price_per_room', 'arrival_month']\n",
      "\n",
      "--- Processing PDP for Cluster 0: no_of_special_requests ---\n",
      "  Type: Numerical\n",
      "  Min: 0.00, Max: 5.00, Mean: 0.58, Std: 0.76\n",
      "‚úì Saved: pdp_cluster0_no_of_special_requests.png\n",
      "\n",
      "--- Processing PDP for Cluster 0: lead_time ---\n",
      "  Type: Numerical\n",
      "  Min: 0.00, Max: 136.30, Mean: 48.35, Std: 38.93\n",
      "‚úì Saved: pdp_cluster0_lead_time.png\n",
      "\n",
      "--- Processing PDP for Cluster 0: avg_price_per_room ---\n",
      "  Type: Numerical\n",
      "  Min: 0.00, Max: 540.00, Mean: 106.40, Std: 37.40\n",
      "‚úì Saved: pdp_cluster0_avg_price_per_room.png\n",
      "\n",
      "--- Processing PDP for Cluster 0: arrival_month ---\n",
      "  Type: Numerical\n",
      "  Min: 1.00, Max: 12.00, Mean: 7.10, Std: 3.16\n",
      "‚úì Saved: pdp_cluster0_arrival_month.png\n",
      "\n",
      "================================================================================\n",
      "CLUSTER 1 - PARTIAL DEPENDENCE PLOTS\n",
      "================================================================================\n",
      "\n",
      "Top 4 features for Cluster 1: ['avg_price_per_room', 'lead_time', 'no_of_special_requests', 'arrival_month']\n",
      "\n",
      "--- Processing PDP for Cluster 1: avg_price_per_room ---\n",
      "  Type: Numerical\n",
      "  Min: 0.00, Max: 365.00, Mean: 103.01, Std: 27.00\n",
      "‚úì Saved: pdp_cluster1_avg_price_per_room.png\n",
      "\n",
      "--- Processing PDP for Cluster 1: lead_time ---\n",
      "  Type: Numerical\n",
      "  Min: 134.76, Max: 443.00, Mean: 221.47, Std: 65.85\n",
      "‚úì Saved: pdp_cluster1_lead_time.png\n",
      "\n",
      "--- Processing PDP for Cluster 1: no_of_special_requests ---\n",
      "  Type: Numerical\n",
      "  Min: 0.00, Max: 4.00, Mean: 0.45, Std: 0.67\n",
      "‚úì Saved: pdp_cluster1_no_of_special_requests.png\n",
      "\n",
      "--- Processing PDP for Cluster 1: arrival_month ---\n",
      "  Type: Numerical\n",
      "  Min: 1.00, Max: 12.00, Mean: 8.15, Std: 2.17\n",
      "‚úì Saved: pdp_cluster1_arrival_month.png\n",
      "\n",
      "================================================================================\n",
      "ANALYSIS COMPLETE!\n",
      "================================================================================\n",
      "\n",
      "Generated Files:\n",
      "  ‚Ä¢ model_metrics_comprehensive.csv\n",
      "  ‚Ä¢ model_comparison_metrics.png\n",
      "  ‚Ä¢ feature_importance_overall.png\n",
      "  ‚Ä¢ feature_importance_cluster_0.png\n",
      "  ‚Ä¢ feature_importance_cluster_1.png\n",
      "  ‚Ä¢ feature_importance_clusters_comparison.png\n",
      "  ‚Ä¢ confusion_matrix_*.png (4 files)\n",
      "  ‚Ä¢ pdp_overall_*.png (Top 4 features - overall model)\n",
      "  ‚Ä¢ pdp_cluster0_*.png (Top 4 features - cluster 0)\n",
      "  ‚Ä¢ pdp_cluster1_*.png (Top 4 features - cluster 1)\n",
      "\n",
      "================================================================================\n",
      "METRICS LEGEND:\n",
      "================================================================================\n",
      "‚Ä¢ Accuracy:  Overall correctness (TP+TN)/(TP+TN+FP+FN)\n",
      "‚Ä¢ Precision: Of predicted cancellations, how many were correct? TP/(TP+FP)\n",
      "‚Ä¢ Recall:    Of actual cancellations, how many did we catch? TP/(TP+FN)\n",
      "‚Ä¢ F1-Score:  Harmonic mean of Precision and Recall (balanced metric)\n",
      "\n",
      "Note: All metrics calculated for 'Canceled' as positive class (class 0)\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, precision_score, recall_score, f1_score\n",
    "from sklearn.inspection import PartialDependenceDisplay\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import shap\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"HOTEL BOOKING CANCELLATION PREDICTION & RECOMMENDATION SYSTEM\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ============================================\n",
    "# LOAD AND PREPROCESS DATA\n",
    "# ============================================\n",
    "df = pd.read_csv('Hotel Reservations.csv')\n",
    "print(f\"\\nOriginal shape: {df.shape}\")\n",
    "df = df.drop('Booking_ID', axis=1)\n",
    "\n",
    "# Fix invalid dates\n",
    "mask_feb29_2018 = ((df['arrival_month'] == 2) & (df['arrival_date'] == 29) & (df['arrival_year'] == 2018))\n",
    "if mask_feb29_2018.any():\n",
    "    print(f\"Correcting {mask_feb29_2018.sum()} invalid dates (2018-02-29 ‚Üí 2018-02-28)\")\n",
    "    df.loc[mask_feb29_2018, 'arrival_date'] = 28\n",
    "\n",
    "# Date feature engineering\n",
    "df['arrival_datetime'] = pd.to_datetime(\n",
    "    df['arrival_year'].astype(str) + '-' + \n",
    "    df['arrival_month'].astype(str).str.zfill(2) + '-' + \n",
    "    df['arrival_date'].astype(str).str.zfill(2), errors='coerce'\n",
    ")\n",
    "df['arrival_dayofweek'] = df['arrival_datetime'].dt.dayofweek\n",
    "df['arrival_day'] = df['arrival_datetime'].dt.day\n",
    "df['arrival_quarter'] = df['arrival_datetime'].dt.quarter\n",
    "df['is_weekend_arrival'] = df['arrival_dayofweek'].isin([5, 6]).astype(int)\n",
    "df = df.drop(['arrival_datetime', 'arrival_date'], axis=1)\n",
    "\n",
    "print(f\"After preprocessing: {len(df)} records\")\n",
    "\n",
    "# ============================================\n",
    "# FEATURE DEFINITIONS\n",
    "# ============================================\n",
    "discrete_numerical_cols = [\n",
    "    'no_of_adults', 'no_of_children', 'no_of_weekend_nights', \n",
    "    'no_of_week_nights', 'arrival_year', 'arrival_month',\n",
    "    'arrival_dayofweek', 'arrival_day', 'arrival_quarter',\n",
    "    'is_weekend_arrival', 'no_of_previous_cancellations', \n",
    "    'no_of_previous_bookings_not_canceled', 'no_of_special_requests'\n",
    "]\n",
    "\n",
    "continuous_numerical_cols = ['lead_time', 'avg_price_per_room']\n",
    "\n",
    "numerical_cols = continuous_numerical_cols + discrete_numerical_cols\n",
    "\n",
    "categorical_cols = [\n",
    "    'type_of_meal_plan', 'room_type_reserved', 'market_segment_type', \n",
    "    'required_car_parking_space', 'repeated_guest'\n",
    "]\n",
    "\n",
    "actionable_features = {\n",
    "    'avg_price_per_room': 'Offer 10-15% discount or complimentary room upgrade',\n",
    "    'type_of_meal_plan': 'Offer discounted meal plan package',\n",
    "    'room_type_reserved': 'Offer free room upgrade to premium category',\n",
    "    'no_of_special_requests': 'Contact guest proactively to gather preferences',\n",
    "    'required_car_parking_space': 'Offer complimentary parking',\n",
    "}\n",
    "\n",
    "# ============================================\n",
    "# TRAIN-TEST SPLIT\n",
    "# ============================================\n",
    "train, test = train_test_split(df, test_size=0.2, random_state=42, stratify=df['booking_status'])\n",
    "print(f\"\\nTrain: {train.shape}, Test: {test.shape}\")\n",
    "\n",
    "x_train_orig = train.drop('booking_status', axis=1)\n",
    "y_train = train['booking_status']\n",
    "x_test_orig = test.drop('booking_status', axis=1)\n",
    "y_test = test['booking_status']\n",
    "\n",
    "# ============================================\n",
    "# PREPROCESSING WITHOUT SCALING - ORIGINAL DATA ONLY\n",
    "# ============================================\n",
    "print(\"\\n‚ö†Ô∏è Using ORIGINAL data (No scaling applied)\")\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('encode', OneHotEncoder(drop='first', handle_unknown='ignore', sparse_output=False), categorical_cols),\n",
    "        ('passthrough', 'passthrough', numerical_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "x_train_processed = preprocessor.fit_transform(x_train_orig)\n",
    "x_test_processed = preprocessor.transform(x_test_orig)\n",
    "\n",
    "# Feature names\n",
    "cat_names = list(preprocessor.named_transformers_['encode'].get_feature_names_out(categorical_cols))\n",
    "all_feature_names = cat_names + numerical_cols\n",
    "\n",
    "x_train_df = pd.DataFrame(x_train_processed, columns=all_feature_names)\n",
    "x_test_df = pd.DataFrame(x_test_processed, columns=all_feature_names)\n",
    "\n",
    "print(f\"Feature columns: {len(all_feature_names)}\")\n",
    "print(f\"  Categorical (encoded): {len(cat_names)}\")\n",
    "print(f\"  Numerical (original): {len(numerical_cols)}\")\n",
    "\n",
    "# Encode target\n",
    "le = LabelEncoder()\n",
    "y_train_encoded = le.fit_transform(y_train)\n",
    "y_test_encoded = le.transform(y_test)\n",
    "\n",
    "print(f\"\\nTarget encoding: {dict(zip(le.classes_, le.transform(le.classes_)))}\")\n",
    "print(f\"  0 = Canceled, 1 = Not_Canceled\")\n",
    "\n",
    "# SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "x_train_resampled, y_train_resampled = smote.fit_resample(x_train_df, y_train_encoded)\n",
    "\n",
    "print(f\"\\nAfter SMOTE: {len(x_train_resampled)} samples\")\n",
    "print(f\"Class balance: {pd.Series(y_train_resampled).value_counts().to_dict()}\")\n",
    "\n",
    "# ============================================\n",
    "# HELPER FUNCTION FOR COMPREHENSIVE METRICS\n",
    "# ============================================\n",
    "def calculate_metrics(y_true, y_pred, dataset_name=\"\", model_name=\"\"):\n",
    "    \"\"\"Calculate comprehensive classification metrics\"\"\"\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    \n",
    "    # For binary classification, we focus on the positive class (0 = Canceled)\n",
    "    precision = precision_score(y_true, y_pred, pos_label=0, zero_division=0)\n",
    "    recall = recall_score(y_true, y_pred, pos_label=0, zero_division=0)\n",
    "    f1 = f1_score(y_true, y_pred, pos_label=0, zero_division=0)\n",
    "    \n",
    "    return {\n",
    "        'Model': model_name,\n",
    "        'Dataset': dataset_name,\n",
    "        'Accuracy': acc,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1-Score': f1\n",
    "    }\n",
    "\n",
    "def print_metrics_table(metrics_list):\n",
    "    \"\"\"Print metrics in a formatted table\"\"\"\n",
    "    df_metrics = pd.DataFrame(metrics_list)\n",
    "    print(\"\\n\" + df_metrics.to_string(index=False))\n",
    "    return df_metrics\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, title, filename):\n",
    "    \"\"\"Plot and save confusion matrix\"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=['Canceled', 'Not_Canceled'],\n",
    "                yticklabels=['Canceled', 'Not_Canceled'])\n",
    "    plt.title(title, fontsize=14, fontweight='bold')\n",
    "    plt.ylabel('Actual', fontsize=12)\n",
    "    plt.xlabel('Predicted', fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "    print(f\"‚úì Saved: {filename}\")\n",
    "    plt.close()\n",
    "\n",
    "# ============================================\n",
    "# APPROACH 1: STANDARD MODELS\n",
    "# ============================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"APPROACH 1: STANDARD MODELS (No Clustering)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "all_metrics = []\n",
    "\n",
    "# Random Forest Standard\n",
    "print(\"\\n--- Random Forest (Standard) ---\")\n",
    "rf_standard = RandomForestClassifier(n_estimators=100, random_state=42, max_depth=20, \n",
    "                                     min_samples_split=5, min_samples_leaf=2)\n",
    "rf_standard.fit(x_train_resampled, y_train_resampled)\n",
    "\n",
    "rf_train_pred = rf_standard.predict(x_train_resampled)\n",
    "rf_test_pred = rf_standard.predict(x_test_df)\n",
    "\n",
    "rf_train_metrics = calculate_metrics(y_train_resampled, rf_train_pred, \"Train\", \"RF Standard\")\n",
    "rf_test_metrics = calculate_metrics(y_test_encoded, rf_test_pred, \"Test\", \"RF Standard\")\n",
    "\n",
    "all_metrics.extend([rf_train_metrics, rf_test_metrics])\n",
    "\n",
    "print(f\"Train - Acc: {rf_train_metrics['Accuracy']:.4f}, Prec: {rf_train_metrics['Precision']:.4f}, Rec: {rf_train_metrics['Recall']:.4f}, F1: {rf_train_metrics['F1-Score']:.4f}\")\n",
    "print(f\"Test  - Acc: {rf_test_metrics['Accuracy']:.4f}, Prec: {rf_test_metrics['Precision']:.4f}, Rec: {rf_test_metrics['Recall']:.4f}, F1: {rf_test_metrics['F1-Score']:.4f}\")\n",
    "\n",
    "plot_confusion_matrix(y_test_encoded, rf_test_pred, \n",
    "                     'Confusion Matrix - RF Standard (Test)', \n",
    "                     'confusion_matrix_rf_standard.png')\n",
    "\n",
    "# XGBoost Standard\n",
    "print(\"\\n--- XGBoost (Standard) ---\")\n",
    "xgb_standard = XGBClassifier(n_estimators=100, random_state=42, max_depth=6, \n",
    "                             learning_rate=0.1, eval_metric='logloss')\n",
    "xgb_standard.fit(x_train_resampled, y_train_resampled)\n",
    "\n",
    "xgb_train_pred = xgb_standard.predict(x_train_resampled)\n",
    "xgb_test_pred = xgb_standard.predict(x_test_df)\n",
    "\n",
    "xgb_train_metrics = calculate_metrics(y_train_resampled, xgb_train_pred, \"Train\", \"XGB Standard\")\n",
    "xgb_test_metrics = calculate_metrics(y_test_encoded, xgb_test_pred, \"Test\", \"XGB Standard\")\n",
    "\n",
    "all_metrics.extend([xgb_train_metrics, xgb_test_metrics])\n",
    "\n",
    "print(f\"Train - Acc: {xgb_train_metrics['Accuracy']:.4f}, Prec: {xgb_train_metrics['Precision']:.4f}, Rec: {xgb_train_metrics['Recall']:.4f}, F1: {xgb_train_metrics['F1-Score']:.4f}\")\n",
    "print(f\"Test  - Acc: {xgb_test_metrics['Accuracy']:.4f}, Prec: {xgb_test_metrics['Precision']:.4f}, Rec: {xgb_test_metrics['Recall']:.4f}, F1: {xgb_test_metrics['F1-Score']:.4f}\")\n",
    "\n",
    "plot_confusion_matrix(y_test_encoded, xgb_test_pred, \n",
    "                     'Confusion Matrix - XGB Standard (Test)', \n",
    "                     'confusion_matrix_xgb_standard.png')\n",
    "\n",
    "# ============================================\n",
    "# APPROACH 2: CLUSTER-BASED MODELS\n",
    "# ============================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"APPROACH 2: CLUSTER-BASED MODELS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "n_clusters = 2\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
    "train_clusters = kmeans.fit_predict(x_train_resampled)\n",
    "test_clusters = kmeans.predict(x_test_df)\n",
    "\n",
    "print(f\"\\nCluster Distribution:\")\n",
    "print(f\"Train: {pd.Series(train_clusters).value_counts().sort_index().to_dict()}\")\n",
    "print(f\"Test: {pd.Series(test_clusters).value_counts().sort_index().to_dict()}\")\n",
    "\n",
    "# Analyze clusters\n",
    "for cid in range(n_clusters):\n",
    "    mask = train_clusters == cid\n",
    "    cancel_rate = (y_train_resampled[mask] == 0).mean()\n",
    "    print(f\"Cluster {cid}: Size={mask.sum()}, Cancellation Rate={cancel_rate:.2%}\")\n",
    "\n",
    "# Train separate models for each cluster\n",
    "rf_cluster_models = {}\n",
    "xgb_cluster_models = {}\n",
    "\n",
    "for cid in range(n_clusters):\n",
    "    print(f\"\\n--- Cluster {cid} ---\")\n",
    "    mask = train_clusters == cid\n",
    "    x_cluster = x_train_resampled[mask]\n",
    "    y_cluster = y_train_resampled[mask]\n",
    "    \n",
    "    # Random Forest\n",
    "    rf_c = RandomForestClassifier(n_estimators=100, random_state=42, max_depth=20,\n",
    "                                  min_samples_split=5, min_samples_leaf=2)\n",
    "    rf_c.fit(x_cluster, y_cluster)\n",
    "    rf_cluster_models[cid] = rf_c\n",
    "    \n",
    "    rf_c_train_pred = rf_c.predict(x_cluster)\n",
    "    rf_c_metrics = calculate_metrics(y_cluster, rf_c_train_pred, f\"Train-C{cid}\", \"RF Cluster\")\n",
    "    all_metrics.append(rf_c_metrics)\n",
    "    \n",
    "    # XGBoost\n",
    "    xgb_c = XGBClassifier(n_estimators=100, random_state=42, max_depth=6,\n",
    "                         learning_rate=0.1, eval_metric='logloss')\n",
    "    xgb_c.fit(x_cluster, y_cluster)\n",
    "    xgb_cluster_models[cid] = xgb_c\n",
    "    \n",
    "    xgb_c_train_pred = xgb_c.predict(x_cluster)\n",
    "    xgb_c_metrics = calculate_metrics(y_cluster, xgb_c_train_pred, f\"Train-C{cid}\", \"XGB Cluster\")\n",
    "    all_metrics.append(xgb_c_metrics)\n",
    "    \n",
    "    print(f\"RF  - Acc: {rf_c_metrics['Accuracy']:.4f}, Prec: {rf_c_metrics['Precision']:.4f}, Rec: {rf_c_metrics['Recall']:.4f}, F1: {rf_c_metrics['F1-Score']:.4f}\")\n",
    "    print(f\"XGB - Acc: {xgb_c_metrics['Accuracy']:.4f}, Prec: {xgb_c_metrics['Precision']:.4f}, Rec: {xgb_c_metrics['Recall']:.4f}, F1: {xgb_c_metrics['F1-Score']:.4f}\")\n",
    "\n",
    "# Test cluster models - Overall\n",
    "print(\"\\n--- Cluster Models: Overall Test Performance ---\")\n",
    "\n",
    "rf_cluster_preds = np.array([rf_cluster_models[c].predict(x_test_df.iloc[[i]])[0] \n",
    "                             for i, c in enumerate(test_clusters)])\n",
    "xgb_cluster_preds = np.array([xgb_cluster_models[c].predict(x_test_df.iloc[[i]])[0] \n",
    "                              for i, c in enumerate(test_clusters)])\n",
    "\n",
    "rf_cluster_test_metrics = calculate_metrics(y_test_encoded, rf_cluster_preds, \"Test\", \"RF Cluster\")\n",
    "xgb_cluster_test_metrics = calculate_metrics(y_test_encoded, xgb_cluster_preds, \"Test\", \"XGB Cluster\")\n",
    "\n",
    "all_metrics.extend([rf_cluster_test_metrics, xgb_cluster_test_metrics])\n",
    "\n",
    "print(f\"RF  - Acc: {rf_cluster_test_metrics['Accuracy']:.4f}, Prec: {rf_cluster_test_metrics['Precision']:.4f}, Rec: {rf_cluster_test_metrics['Recall']:.4f}, F1: {rf_cluster_test_metrics['F1-Score']:.4f}\")\n",
    "print(f\"XGB - Acc: {xgb_cluster_test_metrics['Accuracy']:.4f}, Prec: {xgb_cluster_test_metrics['Precision']:.4f}, Rec: {xgb_cluster_test_metrics['Recall']:.4f}, F1: {xgb_cluster_test_metrics['F1-Score']:.4f}\")\n",
    "\n",
    "plot_confusion_matrix(y_test_encoded, rf_cluster_preds, \n",
    "                     'Confusion Matrix - RF Cluster (Test)', \n",
    "                     'confusion_matrix_rf_cluster.png')\n",
    "\n",
    "plot_confusion_matrix(y_test_encoded, xgb_cluster_preds, \n",
    "                     'Confusion Matrix - XGB Cluster (Test)', \n",
    "                     'confusion_matrix_xgb_cluster.png')\n",
    "\n",
    "# Test accuracy per cluster\n",
    "print(\"\\n--- Per-Cluster Test Performance ---\")\n",
    "for cid in range(n_clusters):\n",
    "    mask = test_clusters == cid\n",
    "    \n",
    "    rf_cluster_c_metrics = calculate_metrics(y_test_encoded[mask], rf_cluster_preds[mask], \n",
    "                                            f\"Test-C{cid}\", \"RF Cluster\")\n",
    "    xgb_cluster_c_metrics = calculate_metrics(y_test_encoded[mask], xgb_cluster_preds[mask], \n",
    "                                             f\"Test-C{cid}\", \"XGB Cluster\")\n",
    "    \n",
    "    all_metrics.extend([rf_cluster_c_metrics, xgb_cluster_c_metrics])\n",
    "    \n",
    "    print(f\"\\nCluster {cid}:\")\n",
    "    print(f\"RF  - Acc: {rf_cluster_c_metrics['Accuracy']:.4f}, Prec: {rf_cluster_c_metrics['Precision']:.4f}, Rec: {rf_cluster_c_metrics['Recall']:.4f}, F1: {rf_cluster_c_metrics['F1-Score']:.4f}\")\n",
    "    print(f\"XGB - Acc: {xgb_cluster_c_metrics['Accuracy']:.4f}, Prec: {xgb_cluster_c_metrics['Precision']:.4f}, Rec: {xgb_cluster_c_metrics['Recall']:.4f}, F1: {xgb_cluster_c_metrics['F1-Score']:.4f}\")\n",
    "\n",
    "# ============================================\n",
    "# COMPREHENSIVE METRICS SUMMARY\n",
    "# ============================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"COMPREHENSIVE METRICS SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "metrics_df = print_metrics_table(all_metrics)\n",
    "\n",
    "# Save metrics to CSV\n",
    "metrics_df.to_csv('model_metrics_comprehensive.csv', index=False)\n",
    "print(\"\\n‚úì Saved: model_metrics_comprehensive.csv\")\n",
    "\n",
    "# ============================================\n",
    "# MODEL COMPARISON\n",
    "# ============================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MODEL COMPARISON (Test Set)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "test_metrics_only = metrics_df[metrics_df['Dataset'].str.contains('Test') & \n",
    "                                ~metrics_df['Dataset'].str.contains('-C')]\n",
    "\n",
    "print(\"\\nTest Performance Comparison:\")\n",
    "print(test_metrics_only.to_string(index=False))\n",
    "\n",
    "# Find best model by F1-Score (most balanced metric)\n",
    "best_by_f1 = test_metrics_only.loc[test_metrics_only['F1-Score'].idxmax()]\n",
    "best_by_acc = test_metrics_only.loc[test_metrics_only['Accuracy'].idxmax()]\n",
    "\n",
    "print(f\"\\nüèÜ BEST MODEL BY F1-SCORE: {best_by_f1['Model']}\")\n",
    "print(f\"   Accuracy: {best_by_f1['Accuracy']:.4f}\")\n",
    "print(f\"   Precision: {best_by_f1['Precision']:.4f}\")\n",
    "print(f\"   Recall: {best_by_f1['Recall']:.4f}\")\n",
    "print(f\"   F1-Score: {best_by_f1['F1-Score']:.4f}\")\n",
    "\n",
    "print(f\"\\nüéØ BEST MODEL BY ACCURACY: {best_by_acc['Model']}\")\n",
    "print(f\"   Accuracy: {best_by_acc['Accuracy']:.4f}\")\n",
    "print(f\"   Precision: {best_by_acc['Precision']:.4f}\")\n",
    "print(f\"   Recall: {best_by_acc['Recall']:.4f}\")\n",
    "print(f\"   F1-Score: {best_by_acc['F1-Score']:.4f}\")\n",
    "\n",
    "# Select best model\n",
    "use_clustering = 'Cluster' in best_by_f1['Model']\n",
    "if use_clustering:\n",
    "    if 'RF' in best_by_f1['Model']:\n",
    "        best_model_dict = rf_cluster_models\n",
    "        model_type = 'RF-Cluster'\n",
    "    else:\n",
    "        best_model_dict = xgb_cluster_models\n",
    "        model_type = 'XGB-Cluster'\n",
    "    best_single_model = None\n",
    "else:\n",
    "    if 'RF' in best_by_f1['Model']:\n",
    "        best_single_model = rf_standard\n",
    "        model_type = 'RF-Standard'\n",
    "    else:\n",
    "        best_single_model = xgb_standard\n",
    "        model_type = 'XGB-Standard'\n",
    "    best_model_dict = None\n",
    "\n",
    "# ============================================\n",
    "# VISUALIZATION: METRICS COMPARISON\n",
    "# ============================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CREATING VISUALIZATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "metrics_to_plot = ['Accuracy', 'Precision', 'Recall', 'F1-Score']\n",
    "colors = ['#2E86AB', '#A23B72', '#F18F01', '#06A77D']\n",
    "\n",
    "for idx, (metric, color) in enumerate(zip(metrics_to_plot, colors)):\n",
    "    ax = axes[idx // 2, idx % 2]\n",
    "    \n",
    "    plot_data = test_metrics_only[['Model', metric]].sort_values(metric, ascending=False)\n",
    "    \n",
    "    bars = ax.barh(range(len(plot_data)), plot_data[metric], color=color, alpha=0.7, edgecolor='black')\n",
    "    ax.set_yticks(range(len(plot_data)))\n",
    "    ax.set_yticklabels(plot_data['Model'])\n",
    "    ax.set_xlabel(metric, fontsize=12, fontweight='bold')\n",
    "    ax.set_title(f'{metric} Comparison (Test Set)', fontsize=13, fontweight='bold')\n",
    "    ax.grid(axis='x', alpha=0.3)\n",
    "    \n",
    "    # Add value labels\n",
    "    for i, (bar, val) in enumerate(zip(bars, plot_data[metric])):\n",
    "        ax.text(val + 0.005, i, f'{val:.4f}', va='center', fontsize=10)\n",
    "\n",
    "plt.suptitle('Model Performance Comparison', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('model_comparison_metrics.png', dpi=300, bbox_inches='tight')\n",
    "print(\"‚úì Saved: model_comparison_metrics.png\")\n",
    "plt.close()\n",
    "\n",
    "# ============================================\n",
    "# FEATURE IMPORTANCE\n",
    "# ============================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FEATURE IMPORTANCE ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if use_clustering:\n",
    "    importances = np.mean([m.feature_importances_ for m in best_model_dict.values()], axis=0)\n",
    "else:\n",
    "    importances = best_single_model.feature_importances_\n",
    "\n",
    "feature_imp_df = pd.DataFrame({\n",
    "    'feature': all_feature_names,\n",
    "    'importance': importances\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\nTop 15 Features (Overall):\")\n",
    "print(feature_imp_df.head(15).to_string(index=False))\n",
    "\n",
    "# Overall feature importance plot\n",
    "plt.figure(figsize=(10, 8))\n",
    "top15 = feature_imp_df.head(15)\n",
    "colors_feat = plt.cm.viridis(np.linspace(0.3, 0.9, len(top15)))\n",
    "plt.barh(range(len(top15)), top15['importance'], color=colors_feat)\n",
    "plt.yticks(range(len(top15)), top15['feature'])\n",
    "plt.xlabel('Importance', fontsize=12)\n",
    "plt.title(f'Feature Importance - {model_type} (Overall)', fontsize=14, fontweight='bold')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.grid(axis='x', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('feature_importance_overall.png', dpi=300, bbox_inches='tight')\n",
    "print(\"‚úì Saved: feature_importance_overall.png\")\n",
    "plt.close()\n",
    "\n",
    "# ============================================\n",
    "# FEATURE IMPORTANCE PER CLUSTER (if clustering used)\n",
    "# ============================================\n",
    "if use_clustering:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"FEATURE IMPORTANCE BY CLUSTER\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    cluster_feature_importance = {}\n",
    "    \n",
    "    for cid in range(n_clusters):\n",
    "        print(f\"\\n--- Cluster {cid} ---\")\n",
    "        model = best_model_dict[cid]\n",
    "        \n",
    "        cluster_imp_df = pd.DataFrame({\n",
    "            'feature': all_feature_names,\n",
    "            'importance': model.feature_importances_\n",
    "        }).sort_values('importance', ascending=False)\n",
    "        \n",
    "        cluster_feature_importance[cid] = cluster_imp_df\n",
    "        \n",
    "        print(f\"\\nTop 15 Features:\")\n",
    "        print(cluster_imp_df.head(15).to_string(index=False))\n",
    "        \n",
    "        # Plot for each cluster\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        top15_cluster = cluster_imp_df.head(15)\n",
    "        colors_cluster = plt.cm.plasma(np.linspace(0.3, 0.9, len(top15_cluster)))\n",
    "        plt.barh(range(len(top15_cluster)), top15_cluster['importance'], color=colors_cluster)\n",
    "        plt.yticks(range(len(top15_cluster)), top15_cluster['feature'])\n",
    "        plt.xlabel('Importance', fontsize=12)\n",
    "        plt.title(f'Feature Importance - {model_type} - Cluster {cid}', fontsize=14, fontweight='bold')\n",
    "        plt.gca().invert_yaxis()\n",
    "        plt.grid(axis='x', alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'feature_importance_cluster_{cid}.png', dpi=300, bbox_inches='tight')\n",
    "        print(f\"‚úì Saved: feature_importance_cluster_{cid}.png\")\n",
    "        plt.close()\n",
    "    \n",
    "    # Comparison plot: Side-by-side top 10 features for both clusters\n",
    "    print(\"\\n--- Creating Cluster Comparison Plot ---\")\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(18, 8))\n",
    "    \n",
    "    for cid in range(n_clusters):\n",
    "        ax = axes[cid]\n",
    "        top10_cluster = cluster_feature_importance[cid].head(10)\n",
    "        colors_comp = plt.cm.viridis(np.linspace(0.3, 0.9, len(top10_cluster)))\n",
    "        \n",
    "        ax.barh(range(len(top10_cluster)), top10_cluster['importance'], color=colors_comp)\n",
    "        ax.set_yticks(range(len(top10_cluster)))\n",
    "        ax.set_yticklabels(top10_cluster['feature'])\n",
    "        ax.set_xlabel('Importance', fontsize=11)\n",
    "        ax.set_title(f'Cluster {cid} - Top 10 Features', fontsize=13, fontweight='bold')\n",
    "        ax.invert_yaxis()\n",
    "        ax.grid(axis='x', alpha=0.3)\n",
    "    \n",
    "    plt.suptitle(f'Feature Importance Comparison Across Clusters', fontsize=16, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('feature_importance_clusters_comparison.png', dpi=300, bbox_inches='tight')\n",
    "    print(\"‚úì Saved: feature_importance_clusters_comparison.png\")\n",
    "    plt.close()\n",
    "\n",
    "# ============================================\n",
    "# PARTIAL DEPENDENCE PLOTS - TOP 4 FEATURES (OVERALL)\n",
    "# ============================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PARTIAL DEPENDENCE PLOTS (Top 4 Most Important Features - Overall)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Get top 4 features (any type)\n",
    "top_4_features = feature_imp_df.head(4)['feature'].tolist()\n",
    "\n",
    "print(f\"\\nCreating PDPs for top 4 features: {top_4_features}\")\n",
    "\n",
    "for feat in top_4_features:\n",
    "    print(f\"\\n--- Processing PDP for: {feat} ---\")\n",
    "    \n",
    "    feat_idx = all_feature_names.index(feat)\n",
    "    \n",
    "    # Determine if feature is numerical or categorical (encoded)\n",
    "    is_numerical = feat in numerical_cols\n",
    "    \n",
    "    if is_numerical:\n",
    "        # Get original values from training data\n",
    "        orig_values = x_train_orig[feat].values\n",
    "        orig_min, orig_max = orig_values.min(), orig_values.max()\n",
    "        orig_mean = orig_values.mean()\n",
    "        orig_std = orig_values.std()\n",
    "        \n",
    "        print(f\"  Type: Numerical\")\n",
    "        print(f\"  Min: {orig_min:.2f}, Max: {orig_max:.2f}, Mean: {orig_mean:.2f}, Std: {orig_std:.2f}\")\n",
    "        \n",
    "        is_continuous = feat in continuous_numerical_cols\n",
    "        \n",
    "        if is_continuous:\n",
    "            # CONTINUOUS FEATURES - Comprehensive 4-panel visualization\n",
    "            fig = plt.figure(figsize=(16, 12))\n",
    "            gs = fig.add_gridspec(2, 2, hspace=0.3, wspace=0.3)\n",
    "            \n",
    "            if use_clustering:\n",
    "                model_for_pdp = list(best_model_dict.values())[0]\n",
    "            else:\n",
    "                model_for_pdp = best_single_model\n",
    "            \n",
    "            # 1. Standard PDP (top-left)\n",
    "            ax1 = fig.add_subplot(gs[0, 0])\n",
    "            display1 = PartialDependenceDisplay.from_estimator(\n",
    "                model_for_pdp, x_train_resampled, features=[feat_idx],\n",
    "                feature_names=all_feature_names, target=1, ax=ax1, grid_resolution=100\n",
    "            )\n",
    "            ax1.set_title(f'Partial Dependence Plot', fontsize=12, fontweight='bold')\n",
    "            ax1.set_xlabel(f'{feat} (Original Scale)', fontsize=11, fontweight='bold')\n",
    "            ax1.grid(alpha=0.3)\n",
    "            \n",
    "            # 2. PDP with confidence intervals (top-right)\n",
    "            ax2 = fig.add_subplot(gs[0, 1])\n",
    "            \n",
    "            # Create range in original scale\n",
    "            orig_range = np.linspace(orig_min, orig_max, 100)\n",
    "            \n",
    "            # Create synthetic data for PD calculation\n",
    "            X_synthetic = np.tile(x_train_resampled.mean(axis=0), (100, 1))\n",
    "            X_synthetic[:, feat_idx] = orig_range\n",
    "            \n",
    "            # Calculate predictions\n",
    "            pd_values = model_for_pdp.predict_proba(X_synthetic)[:, 1]\n",
    "            \n",
    "            # Center the PD values\n",
    "            pd_values_centered = pd_values - pd_values.mean()\n",
    "            \n",
    "            ax2.plot(orig_range, pd_values_centered, linewidth=2.5, color='#2E86AB', label='PDP')\n",
    "            ax2.fill_between(orig_range, pd_values_centered, alpha=0.3, color='#2E86AB')\n",
    "            ax2.set_xlabel(f'{feat} (Original Scale)', fontsize=11, fontweight='bold')\n",
    "            ax2.set_ylabel('Partial Dependence (Centered)', fontsize=11, fontweight='bold')\n",
    "            ax2.set_title(f'PDP with Shaded Area', fontsize=12, fontweight='bold')\n",
    "            ax2.grid(alpha=0.3)\n",
    "            ax2.axhline(y=0, color='red', linestyle='--', alpha=0.5, linewidth=1)\n",
    "            \n",
    "            # Add percentile markers\n",
    "            percentiles = [10, 25, 50, 75, 90]\n",
    "            for p in percentiles:\n",
    "                val = np.percentile(orig_values, p)\n",
    "                ax2.axvline(x=val, color='gray', linestyle=':', alpha=0.3, linewidth=1)\n",
    "                ax2.text(val, ax2.get_ylim()[1]*0.95, f'P{p}', \n",
    "                        ha='center', va='top', fontsize=8, color='gray')\n",
    "            \n",
    "            # 3. Distribution of original values (bottom-left)\n",
    "            ax3 = fig.add_subplot(gs[1, 0])\n",
    "            ax3.hist(orig_values, bins=50, alpha=0.7, color='#A23B72', edgecolor='black')\n",
    "            ax3.set_xlabel(f'{feat} (Original Scale)', fontsize=11, fontweight='bold')\n",
    "            ax3.set_ylabel('Frequency', fontsize=11, fontweight='bold')\n",
    "            ax3.set_title('Distribution in Training Data', fontsize=12, fontweight='bold')\n",
    "            ax3.grid(alpha=0.3, axis='y')\n",
    "            \n",
    "            # Add statistics text\n",
    "            stats_text = f'Mean: {orig_mean:.2f}\\nStd: {orig_std:.2f}\\nMin: {orig_min:.2f}\\nMax: {orig_max:.2f}'\n",
    "            ax3.text(0.98, 0.97, stats_text, transform=ax3.transAxes,\n",
    "                    fontsize=9, verticalalignment='top', horizontalalignment='right',\n",
    "                    bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "            \n",
    "            # 4. ICE plot (bottom-right)\n",
    "            ax4 = fig.add_subplot(gs[1, 1])\n",
    "            \n",
    "            # Sample 50 instances for ICE plot\n",
    "            n_ice_samples = min(50, len(x_train_resampled))\n",
    "            ice_indices = np.random.choice(len(x_train_resampled), n_ice_samples, replace=False)\n",
    "            \n",
    "            # Convert DataFrame to numpy array for indexing\n",
    "            x_train_array = x_train_resampled.values if isinstance(x_train_resampled, pd.DataFrame) else x_train_resampled\n",
    "            \n",
    "            for idx in ice_indices:\n",
    "                X_ice = np.tile(x_train_array[idx], (100, 1))\n",
    "                X_ice[:, feat_idx] = orig_range\n",
    "                ice_pred = model_for_pdp.predict_proba(X_ice)[:, 1]\n",
    "                ax4.plot(orig_range, ice_pred, alpha=0.1, color='blue', linewidth=0.5)\n",
    "            \n",
    "            # Overlay PDP\n",
    "            ax4.plot(orig_range, pd_values, linewidth=3, color='red', label='PDP (Average)')\n",
    "            ax4.set_xlabel(f'{feat} (Original Scale)', fontsize=11, fontweight='bold')\n",
    "            ax4.set_ylabel('Predicted Probability (Not Canceled)', fontsize=11, fontweight='bold')\n",
    "            ax4.set_title('ICE Plot (Individual Conditional Expectation)', fontsize=12, fontweight='bold')\n",
    "            ax4.grid(alpha=0.3)\n",
    "            ax4.legend(loc='best')\n",
    "            \n",
    "            plt.suptitle(f'Comprehensive Analysis: {feat} (Overall Model)', fontsize=16, fontweight='bold', y=0.995)\n",
    "            plt.savefig(f'pdp_overall_{feat}.png', dpi=300, bbox_inches='tight')\n",
    "            print(f\"‚úì Saved: pdp_overall_{feat}.png\")\n",
    "            plt.close()\n",
    "            \n",
    "        else:\n",
    "            # DISCRETE NUMERICAL FEATURES - 2-panel visualization\n",
    "            fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "            \n",
    "            if use_clustering:\n",
    "                model_for_pdp = list(best_model_dict.values())[0]\n",
    "            else:\n",
    "                model_for_pdp = best_single_model\n",
    "            \n",
    "            # PDP plot\n",
    "            display = PartialDependenceDisplay.from_estimator(\n",
    "                model_for_pdp, x_train_resampled, features=[feat_idx],\n",
    "                feature_names=all_feature_names, target=1, ax=axes[0], grid_resolution=50\n",
    "            )\n",
    "            axes[0].set_title(f'PDP: {feat}', fontsize=12, fontweight='bold')\n",
    "            axes[0].set_xlabel(f'{feat} (Original Scale)', fontsize=11, fontweight='bold')\n",
    "            axes[0].grid(alpha=0.3)\n",
    "            \n",
    "            # Distribution\n",
    "            value_counts = pd.Series(orig_values).value_counts().sort_index()\n",
    "            axes[1].bar(value_counts.index, value_counts.values, alpha=0.7, color='#A23B72', edgecolor='black')\n",
    "            axes[1].set_xlabel(f'{feat}', fontsize=11, fontweight='bold')\n",
    "            axes[1].set_ylabel('Frequency', fontsize=11, fontweight='bold')\n",
    "            axes[1].set_title('Distribution in Training Data', fontsize=12, fontweight='bold')\n",
    "            axes[1].grid(alpha=0.3, axis='y')\n",
    "            \n",
    "            # Add statistics text\n",
    "            stats_text = f'Mean: {orig_mean:.2f}\\nStd: {orig_std:.2f}\\nMin: {int(orig_min)}\\nMax: {int(orig_max)}'\n",
    "            axes[1].text(0.98, 0.97, stats_text, transform=axes[1].transAxes,\n",
    "                        fontsize=9, verticalalignment='top', horizontalalignment='right',\n",
    "                        bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "            \n",
    "            plt.suptitle(f'Partial Dependence Analysis: {feat} (Overall Model)', fontsize=14, fontweight='bold')\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f'pdp_overall_{feat}.png', dpi=300, bbox_inches='tight')\n",
    "            print(f\"‚úì Saved: pdp_overall_{feat}.png\")\n",
    "            plt.close()\n",
    "    \n",
    "    else:\n",
    "        # CATEGORICAL (ENCODED) FEATURE\n",
    "        print(f\"  Type: Categorical (One-Hot Encoded)\")\n",
    "        \n",
    "        # For categorical features, show simple PDP\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(10, 6))\n",
    "        \n",
    "        if use_clustering:\n",
    "            model_for_pdp = list(best_model_dict.values())[0]\n",
    "        else:\n",
    "            model_for_pdp = best_single_model\n",
    "        \n",
    "        try:\n",
    "            display = PartialDependenceDisplay.from_estimator(\n",
    "                model_for_pdp, x_train_resampled, features=[feat_idx],\n",
    "                feature_names=all_feature_names, target=1, ax=ax, grid_resolution=20\n",
    "            )\n",
    "            ax.set_title(f'Partial Dependence Plot: {feat} (Overall Model)', fontsize=13, fontweight='bold')\n",
    "            ax.set_xlabel(f'{feat}', fontsize=11, fontweight='bold')\n",
    "            ax.set_ylabel('Partial Dependence', fontsize=11, fontweight='bold')\n",
    "            ax.grid(alpha=0.3)\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f'pdp_overall_{feat.replace(\"/\", \"_\").replace(\" \", \"_\")}.png', dpi=300, bbox_inches='tight')\n",
    "            print(f\"‚úì Saved: pdp_overall_{feat.replace('/', '_').replace(' ', '_')}.png\")\n",
    "            plt.close()\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö† Could not create PDP for {feat}: {str(e)}\")\n",
    "            plt.close()\n",
    "            continue\n",
    "\n",
    "# ============================================\n",
    "# PARTIAL DEPENDENCE PLOTS PER CLUSTER (NEW SECTION)\n",
    "# ============================================\n",
    "if use_clustering:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"PARTIAL DEPENDENCE PLOTS BY CLUSTER (Top 4 Features)\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    for cid in range(n_clusters):\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"CLUSTER {cid} - PARTIAL DEPENDENCE PLOTS\")\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "        # Get cluster-specific data\n",
    "        cluster_mask = train_clusters == cid\n",
    "        x_cluster = x_train_resampled[cluster_mask]\n",
    "        y_cluster = y_train_resampled[cluster_mask]\n",
    "        \n",
    "        # Get cluster-specific model\n",
    "        cluster_model = best_model_dict[cid]\n",
    "        \n",
    "        # Get top 4 features for this cluster\n",
    "        cluster_top_4 = cluster_feature_importance[cid].head(4)['feature'].tolist()\n",
    "        print(f\"\\nTop 4 features for Cluster {cid}: {cluster_top_4}\")\n",
    "        \n",
    "        for feat in cluster_top_4:\n",
    "            print(f\"\\n--- Processing PDP for Cluster {cid}: {feat} ---\")\n",
    "            \n",
    "            feat_idx = all_feature_names.index(feat)\n",
    "            is_numerical = feat in numerical_cols\n",
    "            \n",
    "            if is_numerical:\n",
    "                # Get original values from the RESAMPLED training data (cluster-specific)\n",
    "                # Extract from x_cluster which is already filtered by cluster_mask\n",
    "                x_cluster_df = pd.DataFrame(x_cluster, columns=all_feature_names) if not isinstance(x_cluster, pd.DataFrame) else x_cluster\n",
    "                orig_values_cluster = x_cluster_df[feat].values\n",
    "                orig_min = orig_values_cluster.min()\n",
    "                orig_max = orig_values_cluster.max()\n",
    "                orig_mean = orig_values_cluster.mean()\n",
    "                orig_std = orig_values_cluster.std()\n",
    "                \n",
    "                print(f\"  Type: Numerical\")\n",
    "                print(f\"  Min: {orig_min:.2f}, Max: {orig_max:.2f}, Mean: {orig_mean:.2f}, Std: {orig_std:.2f}\")\n",
    "                \n",
    "                is_continuous = feat in continuous_numerical_cols\n",
    "                \n",
    "                if is_continuous:\n",
    "                    # CONTINUOUS FEATURES - Comprehensive 4-panel visualization\n",
    "                    fig = plt.figure(figsize=(16, 12))\n",
    "                    gs = fig.add_gridspec(2, 2, hspace=0.3, wspace=0.3)\n",
    "                    \n",
    "                    # 1. Standard PDP (top-left)\n",
    "                    ax1 = fig.add_subplot(gs[0, 0])\n",
    "                    display1 = PartialDependenceDisplay.from_estimator(\n",
    "                        cluster_model, x_cluster, features=[feat_idx],\n",
    "                        feature_names=all_feature_names, target=1, ax=ax1, grid_resolution=100\n",
    "                    )\n",
    "                    ax1.set_title(f'Partial Dependence Plot - Cluster {cid}', fontsize=12, fontweight='bold')\n",
    "                    ax1.set_xlabel(f'{feat} (Original Scale)', fontsize=11, fontweight='bold')\n",
    "                    ax1.grid(alpha=0.3)\n",
    "                    \n",
    "                    # 2. PDP with confidence intervals (top-right)\n",
    "                    ax2 = fig.add_subplot(gs[0, 1])\n",
    "                    \n",
    "                    # Create range in original scale\n",
    "                    orig_range = np.linspace(orig_min, orig_max, 100)\n",
    "                    \n",
    "                    # Create synthetic data for PD calculation\n",
    "                    x_cluster_array = x_cluster.values if isinstance(x_cluster, pd.DataFrame) else x_cluster\n",
    "                    X_synthetic = np.tile(x_cluster_array.mean(axis=0), (100, 1))\n",
    "                    X_synthetic[:, feat_idx] = orig_range\n",
    "                    \n",
    "                    # Calculate predictions\n",
    "                    pd_values = cluster_model.predict_proba(X_synthetic)[:, 1]\n",
    "                    \n",
    "                    # Center the PD values\n",
    "                    pd_values_centered = pd_values - pd_values.mean()\n",
    "                    \n",
    "                    ax2.plot(orig_range, pd_values_centered, linewidth=2.5, color='#2E86AB', label='PDP')\n",
    "                    ax2.fill_between(orig_range, pd_values_centered, alpha=0.3, color='#2E86AB')\n",
    "                    ax2.set_xlabel(f'{feat} (Original Scale)', fontsize=11, fontweight='bold')\n",
    "                    ax2.set_ylabel('Partial Dependence (Centered)', fontsize=11, fontweight='bold')\n",
    "                    ax2.set_title(f'PDP with Shaded Area - Cluster {cid}', fontsize=12, fontweight='bold')\n",
    "                    ax2.grid(alpha=0.3)\n",
    "                    ax2.axhline(y=0, color='red', linestyle='--', alpha=0.5, linewidth=1)\n",
    "                    \n",
    "                    # Add percentile markers\n",
    "                    percentiles = [10, 25, 50, 75, 90]\n",
    "                    for p in percentiles:\n",
    "                        val = np.percentile(orig_values_cluster, p)\n",
    "                        ax2.axvline(x=val, color='gray', linestyle=':', alpha=0.3, linewidth=1)\n",
    "                        ax2.text(val, ax2.get_ylim()[1]*0.95, f'P{p}', \n",
    "                                ha='center', va='top', fontsize=8, color='gray')\n",
    "                    \n",
    "                    # 3. Distribution of original values (bottom-left)\n",
    "                    ax3 = fig.add_subplot(gs[1, 0])\n",
    "                    ax3.hist(orig_values_cluster, bins=50, alpha=0.7, color='#A23B72', edgecolor='black')\n",
    "                    ax3.set_xlabel(f'{feat} (Original Scale)', fontsize=11, fontweight='bold')\n",
    "                    ax3.set_ylabel('Frequency', fontsize=11, fontweight='bold')\n",
    "                    ax3.set_title(f'Distribution in Cluster {cid}', fontsize=12, fontweight='bold')\n",
    "                    ax3.grid(alpha=0.3, axis='y')\n",
    "                    \n",
    "                    # Add statistics text\n",
    "                    stats_text = f'Mean: {orig_mean:.2f}\\nStd: {orig_std:.2f}\\nMin: {orig_min:.2f}\\nMax: {orig_max:.2f}'\n",
    "                    ax3.text(0.98, 0.97, stats_text, transform=ax3.transAxes,\n",
    "                            fontsize=9, verticalalignment='top', horizontalalignment='right',\n",
    "                            bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "                    \n",
    "                    # 4. ICE plot (bottom-right)\n",
    "                    ax4 = fig.add_subplot(gs[1, 1])\n",
    "                    \n",
    "                    # Sample 50 instances for ICE plot\n",
    "                    n_ice_samples = min(50, len(x_cluster))\n",
    "                    ice_indices = np.random.choice(len(x_cluster), n_ice_samples, replace=False)\n",
    "                    \n",
    "                    for idx in ice_indices:\n",
    "                        X_ice = np.tile(x_cluster_array[idx], (100, 1))\n",
    "                        X_ice[:, feat_idx] = orig_range\n",
    "                        ice_pred = cluster_model.predict_proba(X_ice)[:, 1]\n",
    "                        ax4.plot(orig_range, ice_pred, alpha=0.1, color='blue', linewidth=0.5)\n",
    "                    \n",
    "                    # Overlay PDP\n",
    "                    ax4.plot(orig_range, pd_values, linewidth=3, color='red', label='PDP (Average)')\n",
    "                    ax4.set_xlabel(f'{feat} (Original Scale)', fontsize=11, fontweight='bold')\n",
    "                    ax4.set_ylabel('Predicted Probability (Not Canceled)', fontsize=11, fontweight='bold')\n",
    "                    ax4.set_title(f'ICE Plot - Cluster {cid}', fontsize=12, fontweight='bold')\n",
    "                    ax4.grid(alpha=0.3)\n",
    "                    ax4.legend(loc='best')\n",
    "                    \n",
    "                    plt.suptitle(f'Comprehensive Analysis: {feat} - Cluster {cid}', fontsize=16, fontweight='bold', y=0.995)\n",
    "                    plt.savefig(f'pdp_cluster{cid}_{feat}.png', dpi=300, bbox_inches='tight')\n",
    "                    print(f\"‚úì Saved: pdp_cluster{cid}_{feat}.png\")\n",
    "                    plt.close()\n",
    "                    \n",
    "                else:\n",
    "                    # DISCRETE NUMERICAL FEATURES - 2-panel visualization\n",
    "                    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "                    \n",
    "                    # PDP plot\n",
    "                    display = PartialDependenceDisplay.from_estimator(\n",
    "                        cluster_model, x_cluster, features=[feat_idx],\n",
    "                        feature_names=all_feature_names, target=1, ax=axes[0], grid_resolution=50\n",
    "                    )\n",
    "                    axes[0].set_title(f'PDP: {feat} - Cluster {cid}', fontsize=12, fontweight='bold')\n",
    "                    axes[0].set_xlabel(f'{feat} (Original Scale)', fontsize=11, fontweight='bold')\n",
    "                    axes[0].grid(alpha=0.3)\n",
    "                    \n",
    "                    # Distribution\n",
    "                    value_counts = pd.Series(orig_values_cluster).value_counts().sort_index()\n",
    "                    axes[1].bar(value_counts.index, value_counts.values, alpha=0.7, color='#A23B72', edgecolor='black')\n",
    "                    axes[1].set_xlabel(f'{feat}', fontsize=11, fontweight='bold')\n",
    "                    axes[1].set_ylabel('Frequency', fontsize=11, fontweight='bold')\n",
    "                    axes[1].set_title(f'Distribution in Cluster {cid}', fontsize=12, fontweight='bold')\n",
    "                    axes[1].grid(alpha=0.3, axis='y')\n",
    "                    \n",
    "                    # Add statistics text\n",
    "                    stats_text = f'Mean: {orig_mean:.2f}\\nStd: {orig_std:.2f}\\nMin: {int(orig_min)}\\nMax: {int(orig_max)}'\n",
    "                    axes[1].text(0.98, 0.97, stats_text, transform=axes[1].transAxes,\n",
    "                            fontsize=9, verticalalignment='top', horizontalalignment='right',\n",
    "                            bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "                    \n",
    "                    plt.suptitle(f'Partial Dependence Analysis: {feat} - Cluster {cid}', fontsize=14, fontweight='bold')\n",
    "                    plt.tight_layout()\n",
    "                    plt.savefig(f'pdp_cluster{cid}_{feat}.png', dpi=300, bbox_inches='tight')\n",
    "                    print(f\"‚úì Saved: pdp_cluster{cid}_{feat}.png\")\n",
    "                    plt.close()\n",
    "            \n",
    "            else:\n",
    "                # CATEGORICAL (ENCODED) FEATURE\n",
    "                print(f\"  Type: Categorical (One-Hot Encoded)\")\n",
    "                \n",
    "                # For categorical features, show simple PDP\n",
    "                fig, ax = plt.subplots(1, 1, figsize=(10, 6))\n",
    "                \n",
    "                try:\n",
    "                    display = PartialDependenceDisplay.from_estimator(\n",
    "                        cluster_model, x_cluster, features=[feat_idx],\n",
    "                        feature_names=all_feature_names, target=1, ax=ax, grid_resolution=20\n",
    "                    )\n",
    "                    ax.set_title(f'Partial Dependence Plot: {feat} - Cluster {cid}', fontsize=13, fontweight='bold')\n",
    "                    ax.set_xlabel(f'{feat}', fontsize=11, fontweight='bold')\n",
    "                    ax.set_ylabel('Partial Dependence', fontsize=11, fontweight='bold')\n",
    "                    ax.grid(alpha=0.3)\n",
    "                    \n",
    "                    plt.tight_layout()\n",
    "                    plt.savefig(f'pdp_cluster{cid}_{feat.replace(\"/\", \"_\").replace(\" \", \"_\")}.png', dpi=300, bbox_inches='tight')\n",
    "                    print(f\"‚úì Saved: pdp_cluster{cid}_{feat.replace('/', '_').replace(' ', '_')}.png\")\n",
    "                    plt.close()\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ö† Could not create PDP for {feat} in Cluster {cid}: {str(e)}\")\n",
    "                    plt.close()\n",
    "                    continue\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ANALYSIS COMPLETE!\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nGenerated Files:\")\n",
    "print(\"  ‚Ä¢ model_metrics_comprehensive.csv\")\n",
    "print(\"  ‚Ä¢ model_comparison_metrics.png\")\n",
    "print(\"  ‚Ä¢ feature_importance_overall.png\")\n",
    "if use_clustering:\n",
    "    print(f\"  ‚Ä¢ feature_importance_cluster_0.png\")\n",
    "    print(f\"  ‚Ä¢ feature_importance_cluster_1.png\")\n",
    "    print(f\"  ‚Ä¢ feature_importance_clusters_comparison.png\")\n",
    "print(\"  ‚Ä¢ confusion_matrix_*.png (4 files)\")\n",
    "print(\"  ‚Ä¢ pdp_overall_*.png (Top 4 features - overall model)\")\n",
    "if use_clustering:\n",
    "    print(\"  ‚Ä¢ pdp_cluster0_*.png (Top 4 features - cluster 0)\")\n",
    "    print(\"  ‚Ä¢ pdp_cluster1_*.png (Top 4 features - cluster 1)\")\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"METRICS LEGEND:\")\n",
    "print(\"=\"*80)\n",
    "print(\"‚Ä¢ Accuracy:  Overall correctness (TP+TN)/(TP+TN+FP+FN)\")\n",
    "print(\"‚Ä¢ Precision: Of predicted cancellations, how many were correct? TP/(TP+FP)\")\n",
    "print(\"‚Ä¢ Recall:    Of actual cancellations, how many did we catch? TP/(TP+FN)\")\n",
    "print(\"‚Ä¢ F1-Score:  Harmonic mean of Precision and Recall (balanced metric)\")\n",
    "print(\"\\nNote: All metrics calculated for 'Canceled' as positive class (class 0)\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c98abd7-2b2b-484d-9b30-b5e315d7c270",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
